{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ML Mini project"
      ],
      "metadata": {
        "id": "P0Xp297oorJj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wpd1WW5aU2e"
      },
      "source": [
        "#### Importing Libraries and the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "rHFjK_pNaU2e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "z72wEKx6aU2e"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"sign_mnist_train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "RRkvJvYHo3P8",
        "outputId": "e993f74a-da4c-4b70-e08c-a171eda4a237"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0          3     107     118     127     134     139     143     146     150   \n",
              "1          6     155     157     156     156     156     157     156     158   \n",
              "2          2     187     188     188     187     187     186     187     188   \n",
              "3          2     211     211     212     212     211     210     211     210   \n",
              "4         13     164     167     170     172     176     179     180     184   \n",
              "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "27450     13     189     189     190     190     192     193     193     193   \n",
              "27451     23     151     154     157     158     160     161     163     164   \n",
              "27452     18     174     174     174     174     174     175     175     174   \n",
              "27453     17     177     181     184     185     187     189     190     191   \n",
              "27454     23     179     180     180     180     182     181     182     183   \n",
              "\n",
              "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
              "0         153  ...       207       207       207       207       206   \n",
              "1         158  ...        69       149       128        87        94   \n",
              "2         187  ...       202       201       200       199       198   \n",
              "3         210  ...       235       234       233       231       230   \n",
              "4         185  ...        92       105       105       108       133   \n",
              "...       ...  ...       ...       ...       ...       ...       ...   \n",
              "27450     193  ...       132       165        99        77        52   \n",
              "27451     166  ...       198       198       198       198       198   \n",
              "27452     173  ...       121       196       209       208       206   \n",
              "27453     191  ...       119        56        27        58       102   \n",
              "27454     182  ...       108       132       170       194       214   \n",
              "\n",
              "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
              "0           206       206       204       203       202  \n",
              "1           163       175       103       135       149  \n",
              "2           199       198       195       194       195  \n",
              "3           226       225       222       229       163  \n",
              "4           163       157       163       164       179  \n",
              "...         ...       ...       ...       ...       ...  \n",
              "27450       200       234       200       222       225  \n",
              "27451       196       195       195       195       194  \n",
              "27452       204       203       202       200       200  \n",
              "27453        79        47        64        87        93  \n",
              "27454       203       197       205       209       215  \n",
              "\n",
              "[27455 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82fb9f74-6ea2-414b-8e89-cf0a877329bd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>107</td>\n",
              "      <td>118</td>\n",
              "      <td>127</td>\n",
              "      <td>134</td>\n",
              "      <td>139</td>\n",
              "      <td>143</td>\n",
              "      <td>146</td>\n",
              "      <td>150</td>\n",
              "      <td>153</td>\n",
              "      <td>...</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>155</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>158</td>\n",
              "      <td>158</td>\n",
              "      <td>...</td>\n",
              "      <td>69</td>\n",
              "      <td>149</td>\n",
              "      <td>128</td>\n",
              "      <td>87</td>\n",
              "      <td>94</td>\n",
              "      <td>163</td>\n",
              "      <td>175</td>\n",
              "      <td>103</td>\n",
              "      <td>135</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>187</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>...</td>\n",
              "      <td>202</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>210</td>\n",
              "      <td>...</td>\n",
              "      <td>235</td>\n",
              "      <td>234</td>\n",
              "      <td>233</td>\n",
              "      <td>231</td>\n",
              "      <td>230</td>\n",
              "      <td>226</td>\n",
              "      <td>225</td>\n",
              "      <td>222</td>\n",
              "      <td>229</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>164</td>\n",
              "      <td>167</td>\n",
              "      <td>170</td>\n",
              "      <td>172</td>\n",
              "      <td>176</td>\n",
              "      <td>179</td>\n",
              "      <td>180</td>\n",
              "      <td>184</td>\n",
              "      <td>185</td>\n",
              "      <td>...</td>\n",
              "      <td>92</td>\n",
              "      <td>105</td>\n",
              "      <td>105</td>\n",
              "      <td>108</td>\n",
              "      <td>133</td>\n",
              "      <td>163</td>\n",
              "      <td>157</td>\n",
              "      <td>163</td>\n",
              "      <td>164</td>\n",
              "      <td>179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27450</th>\n",
              "      <td>13</td>\n",
              "      <td>189</td>\n",
              "      <td>189</td>\n",
              "      <td>190</td>\n",
              "      <td>190</td>\n",
              "      <td>192</td>\n",
              "      <td>193</td>\n",
              "      <td>193</td>\n",
              "      <td>193</td>\n",
              "      <td>193</td>\n",
              "      <td>...</td>\n",
              "      <td>132</td>\n",
              "      <td>165</td>\n",
              "      <td>99</td>\n",
              "      <td>77</td>\n",
              "      <td>52</td>\n",
              "      <td>200</td>\n",
              "      <td>234</td>\n",
              "      <td>200</td>\n",
              "      <td>222</td>\n",
              "      <td>225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27451</th>\n",
              "      <td>23</td>\n",
              "      <td>151</td>\n",
              "      <td>154</td>\n",
              "      <td>157</td>\n",
              "      <td>158</td>\n",
              "      <td>160</td>\n",
              "      <td>161</td>\n",
              "      <td>163</td>\n",
              "      <td>164</td>\n",
              "      <td>166</td>\n",
              "      <td>...</td>\n",
              "      <td>198</td>\n",
              "      <td>198</td>\n",
              "      <td>198</td>\n",
              "      <td>198</td>\n",
              "      <td>198</td>\n",
              "      <td>196</td>\n",
              "      <td>195</td>\n",
              "      <td>195</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27452</th>\n",
              "      <td>18</td>\n",
              "      <td>174</td>\n",
              "      <td>174</td>\n",
              "      <td>174</td>\n",
              "      <td>174</td>\n",
              "      <td>174</td>\n",
              "      <td>175</td>\n",
              "      <td>175</td>\n",
              "      <td>174</td>\n",
              "      <td>173</td>\n",
              "      <td>...</td>\n",
              "      <td>121</td>\n",
              "      <td>196</td>\n",
              "      <td>209</td>\n",
              "      <td>208</td>\n",
              "      <td>206</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "      <td>200</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27453</th>\n",
              "      <td>17</td>\n",
              "      <td>177</td>\n",
              "      <td>181</td>\n",
              "      <td>184</td>\n",
              "      <td>185</td>\n",
              "      <td>187</td>\n",
              "      <td>189</td>\n",
              "      <td>190</td>\n",
              "      <td>191</td>\n",
              "      <td>191</td>\n",
              "      <td>...</td>\n",
              "      <td>119</td>\n",
              "      <td>56</td>\n",
              "      <td>27</td>\n",
              "      <td>58</td>\n",
              "      <td>102</td>\n",
              "      <td>79</td>\n",
              "      <td>47</td>\n",
              "      <td>64</td>\n",
              "      <td>87</td>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27454</th>\n",
              "      <td>23</td>\n",
              "      <td>179</td>\n",
              "      <td>180</td>\n",
              "      <td>180</td>\n",
              "      <td>180</td>\n",
              "      <td>182</td>\n",
              "      <td>181</td>\n",
              "      <td>182</td>\n",
              "      <td>183</td>\n",
              "      <td>182</td>\n",
              "      <td>...</td>\n",
              "      <td>108</td>\n",
              "      <td>132</td>\n",
              "      <td>170</td>\n",
              "      <td>194</td>\n",
              "      <td>214</td>\n",
              "      <td>203</td>\n",
              "      <td>197</td>\n",
              "      <td>205</td>\n",
              "      <td>209</td>\n",
              "      <td>215</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27455 rows × 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82fb9f74-6ea2-414b-8e89-cf0a877329bd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-82fb9f74-6ea2-414b-8e89-cf0a877329bd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-82fb9f74-6ea2-414b-8e89-cf0a877329bd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-780733ad-5051-4147-ae0c-357dc3722583\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-780733ad-5051-4147-ae0c-357dc3722583')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-780733ad-5051-4147-ae0c-357dc3722583 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_02327de3-cdd7-46bb-80bb-4fdb7aa18d52\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_02327de3-cdd7-46bb-80bb-4fdb7aa18d52 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xpsTq1vLoyzN"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4MuL4vFaU2f"
      },
      "source": [
        "#### Creating a DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "x6C-xrabaU2f"
      },
      "outputs": [],
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Qzq3CVC-aU2f",
        "outputId": "2d2399ad-866d-42b8-eb2c-55a2a065f4a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([27455, 1, 784]), tensor([ 3,  6,  2,  ..., 18, 17, 23]))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "X_train = torch.tensor(df.iloc[:,1:].to_numpy(),dtype=torch.float32).unsqueeze(-1).permute(0,2,1)\n",
        "y_train = torch.tensor(df.iloc[:,0].to_numpy())\n",
        "X_train.shape,y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "SUkDe0CYaU2g"
      },
      "outputs": [],
      "source": [
        "train_data = MyDataset(X_train,y_train)\n",
        "test_data = MyDataset(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "XVXGh60MaU2g"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "ZmwVk59taU2g"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "eBR9sZ54aU2g",
        "outputId": "ec63fa76-788b-4784-a00e-829c1ea0ec8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "fBuXlL8RaU2g"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_data,batch_size=8,shuffle=True,pin_memory=True)\n",
        "test_dataloader = DataLoader(test_data,batch_size=8,shuffle=True,pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Ir_P6ZvnaU2h",
        "outputId": "bd0ea8ed-8c32-4051-f46b-cf444b4acac6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[[166., 166., 166.,  ..., 152., 159., 159.]],\n",
              " \n",
              "         [[186., 188., 191.,  ..., 125., 108.,  79.]],\n",
              " \n",
              "         [[120., 121., 121.,  ..., 139., 137., 137.]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[197., 197., 197.,  ...,  30.,  26.,  26.]],\n",
              " \n",
              "         [[133., 134., 137.,  ..., 173., 173., 172.]],\n",
              " \n",
              "         [[142., 155., 165.,  ..., 132., 135., 136.]]]),\n",
              " tensor([14, 17, 11, 11, 18,  6,  6, 11])]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "next(iter(train_dataloader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYspETbmaU2h"
      },
      "source": [
        "#### The CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "2b6lJvc3aU2h"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self,input_shape,hidden_units,output_shape):\n",
        "        super().__init__()\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=input_shape,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2,\n",
        "                         stride=2)\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv1d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2,stride=2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=hidden_units*7*7,\n",
        "                      out_features=output_shape),\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EL90A-FaU2h"
      },
      "source": [
        "####Train Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "9q9vHM9laU2h"
      },
      "outputs": [],
      "source": [
        "def train_model(model_0,train_dataloader: DataLoader, test_dataloader: DataLoader, optimizer: torch.optim.Optimizer, loss_fn: torch.nn.Module, accuracy_fn,\n",
        "          epochs: int,verbose: bool = True):\n",
        "        results = []\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"Epoch: {epoch}\\n-------\")\n",
        "            metrics = {\n",
        "                 \"train_loss\": [],\n",
        "                 \"test_loss\": [],\n",
        "                 \"train_acc\": [],\n",
        "                 \"test_acc\": []\n",
        "            }\n",
        "            train_loss,train_acc = 0,0\n",
        "            for batch, (X, y) in enumerate(train_dataloader):\n",
        "                X,y = X.to(device),y.to(device)\n",
        "                model_0.train()\n",
        "                # 1. Forward pass\n",
        "                y_pred = model_0(X)\n",
        "\n",
        "                # 2. Calculate loss (per batch)\n",
        "                loss = loss_fn(y_pred, y)\n",
        "                train_loss += loss # accumulatively add up the loss per epoch\n",
        "                train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "                # 3. Optimizer zero grad\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 4. Loss backward\n",
        "                loss.backward()\n",
        "\n",
        "                # 5. Optimizer step\n",
        "                optimizer.step()\n",
        "\n",
        "                # Print out how many samples have been seen\n",
        "                if batch % 400 == 0:\n",
        "                    print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
        "\n",
        "            # Divide total train loss by length of train dataloader (average loss per batch per epoch)\n",
        "            train_loss /= len(train_dataloader)\n",
        "            train_acc /= len(train_dataloader)\n",
        "            metrics[\"train_loss\"].append(train_loss.detach().to(\"cpu\").numpy())\n",
        "            metrics[\"train_acc\"].append(train_acc)\n",
        "            ### Testing\n",
        "            # Setup variables for accumulatively adding up loss and accuracy\n",
        "            test_loss, test_acc = 0, 0\n",
        "            model_0.eval()\n",
        "            with torch.inference_mode():\n",
        "                for X, y in test_dataloader:\n",
        "                    X,y = X.to(device),y.to(device)\n",
        "                    # 1. Forward pass\n",
        "                    test_pred = model_0(X)\n",
        "\n",
        "                    # 2. Calculate loss (accumatively)\n",
        "                    test_loss += loss_fn(test_pred, y) # accumulatively add up the loss per epoch\n",
        "\n",
        "                    # 3. Calculate accuracy (preds need to be same as y_true)\n",
        "                    test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "                # Calculations on test metrics need to happen inside torch.inference_mode()\n",
        "                # Divide total test loss by length of test dataloader (per batch)\n",
        "                test_loss /= len(test_dataloader)\n",
        "\n",
        "                # Divide total accuracy by length of test dataloader (per batch)\n",
        "                test_acc /= len(test_dataloader)\n",
        "\n",
        "                ## Print out what's happening\n",
        "\n",
        "\n",
        "\n",
        "                metrics[\"test_acc\"].append(test_acc)\n",
        "                metrics[\"test_loss\"].append(test_loss.detach().to(\"cpu\").numpy())\n",
        "\n",
        "\n",
        "            print(f\"\\nTrain loss: {train_loss:.5f}, Train Accuracy: {train_acc: .4f} | Test loss: {test_loss:.5f}, Test Accuracy: {test_acc:.2f}%\\n\")\n",
        "            results.append(metrics)\n",
        "\n",
        "\n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "y4XtviFNaU2h"
      },
      "outputs": [],
      "source": [
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item()\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU5o69YWaU2h"
      },
      "source": [
        "#### Training the Model for 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "QIoTRdwgaU2h"
      },
      "outputs": [],
      "source": [
        "model = CNN(1,12,26).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "5db7X21saU2h",
        "outputId": "20c6535d-01e0-4da1-8cee-fbbc425292fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (block_1): Sequential(\n",
              "    (0): Conv1d(1, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block_2): Sequential(\n",
              "    (0): Conv1d(12, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (1): ReLU()\n",
              "    (2): Conv1d(12, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=588, out_features=26, bias=True)\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "QfWvLmBIaU2h"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Yon0xqL0aU2h",
        "outputId": "c13f59b7-4c60-45dd-d95a-4d56523a0d6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "-------\n",
            "Looked at 0/27455 samples\n",
            "Looked at 3200/27455 samples\n",
            "Looked at 6400/27455 samples\n",
            "Looked at 9600/27455 samples\n",
            "Looked at 12800/27455 samples\n",
            "Looked at 16000/27455 samples\n",
            "Looked at 19200/27455 samples\n",
            "Looked at 22400/27455 samples\n",
            "Looked at 25600/27455 samples\n",
            "\n",
            "Train loss: 0.93538, Train Accuracy:  70.4618 | Test loss: 0.07374, Test Accuracy: 97.84%\n",
            "\n",
            "Epoch: 1\n",
            "-------\n",
            "Looked at 0/27455 samples\n",
            "Looked at 3200/27455 samples\n",
            "Looked at 6400/27455 samples\n",
            "Looked at 9600/27455 samples\n",
            "Looked at 12800/27455 samples\n",
            "Looked at 16000/27455 samples\n",
            "Looked at 19200/27455 samples\n",
            "Looked at 22400/27455 samples\n",
            "Looked at 25600/27455 samples\n",
            "\n",
            "Train loss: 0.46174, Train Accuracy:  82.3166 | Test loss: 0.03131, Test Accuracy: 99.20%\n",
            "\n",
            "Epoch: 2\n",
            "-------\n",
            "Looked at 0/27455 samples\n",
            "Looked at 3200/27455 samples\n",
            "Looked at 6400/27455 samples\n",
            "Looked at 9600/27455 samples\n",
            "Looked at 12800/27455 samples\n",
            "Looked at 16000/27455 samples\n",
            "Looked at 19200/27455 samples\n",
            "Looked at 22400/27455 samples\n",
            "Looked at 25600/27455 samples\n",
            "\n",
            "Train loss: 0.42987, Train Accuracy:  82.2183 | Test loss: 0.01173, Test Accuracy: 99.64%\n",
            "\n",
            "Epoch: 3\n",
            "-------\n",
            "Looked at 0/27455 samples\n",
            "Looked at 3200/27455 samples\n",
            "Looked at 6400/27455 samples\n",
            "Looked at 9600/27455 samples\n",
            "Looked at 12800/27455 samples\n",
            "Looked at 16000/27455 samples\n",
            "Looked at 19200/27455 samples\n",
            "Looked at 22400/27455 samples\n",
            "Looked at 25600/27455 samples\n",
            "\n",
            "Train loss: 0.40641, Train Accuracy:  82.9291 | Test loss: 0.01817, Test Accuracy: 99.42%\n",
            "\n",
            "Epoch: 4\n",
            "-------\n",
            "Looked at 0/27455 samples\n",
            "Looked at 3200/27455 samples\n",
            "Looked at 6400/27455 samples\n",
            "Looked at 9600/27455 samples\n",
            "Looked at 12800/27455 samples\n",
            "Looked at 16000/27455 samples\n",
            "Looked at 19200/27455 samples\n",
            "Looked at 22400/27455 samples\n",
            "Looked at 25600/27455 samples\n",
            "\n",
            "Train loss: 0.39842, Train Accuracy:  82.8344 | Test loss: 0.00706, Test Accuracy: 99.81%\n",
            "\n",
            "Epoch: 5\n",
            "-------\n",
            "Looked at 0/27455 samples\n",
            "Looked at 3200/27455 samples\n",
            "Looked at 6400/27455 samples\n",
            "Looked at 9600/27455 samples\n",
            "Looked at 12800/27455 samples\n",
            "Looked at 16000/27455 samples\n",
            "Looked at 19200/27455 samples\n",
            "Looked at 22400/27455 samples\n",
            "Looked at 25600/27455 samples\n",
            "\n",
            "Train loss: 0.38980, Train Accuracy:  83.4785 | Test loss: 0.00299, Test Accuracy: 99.89%\n",
            "\n",
            "Epoch: 6\n",
            "-------\n",
            "Looked at 0/27455 samples\n",
            "Looked at 3200/27455 samples\n",
            "Looked at 6400/27455 samples\n",
            "Looked at 9600/27455 samples\n",
            "Looked at 12800/27455 samples\n",
            "Looked at 16000/27455 samples\n",
            "Looked at 19200/27455 samples\n",
            "Looked at 22400/27455 samples\n",
            "Looked at 25600/27455 samples\n",
            "\n",
            "Train loss: 0.38961, Train Accuracy:  82.8916 | Test loss: 0.01563, Test Accuracy: 99.41%\n",
            "\n",
            "Epoch: 7\n",
            "-------\n",
            "Looked at 0/27455 samples\n",
            "Looked at 3200/27455 samples\n",
            "Looked at 6400/27455 samples\n",
            "Looked at 9600/27455 samples\n",
            "Looked at 12800/27455 samples\n",
            "Looked at 16000/27455 samples\n",
            "Looked at 19200/27455 samples\n",
            "Looked at 22400/27455 samples\n",
            "Looked at 25600/27455 samples\n",
            "\n",
            "Train loss: 0.38472, Train Accuracy:  83.3661 | Test loss: 0.00227, Test Accuracy: 99.96%\n",
            "\n",
            "Epoch: 8\n",
            "-------\n",
            "Looked at 0/27455 samples\n",
            "Looked at 3200/27455 samples\n",
            "Looked at 6400/27455 samples\n",
            "Looked at 9600/27455 samples\n",
            "Looked at 12800/27455 samples\n",
            "Looked at 16000/27455 samples\n",
            "Looked at 19200/27455 samples\n",
            "Looked at 22400/27455 samples\n",
            "Looked at 25600/27455 samples\n",
            "\n",
            "Train loss: 0.37321, Train Accuracy:  83.5732 | Test loss: 0.00093, Test Accuracy: 99.97%\n",
            "\n",
            "Epoch: 9\n",
            "-------\n",
            "Looked at 0/27455 samples\n",
            "Looked at 3200/27455 samples\n",
            "Looked at 6400/27455 samples\n",
            "Looked at 9600/27455 samples\n",
            "Looked at 12800/27455 samples\n",
            "Looked at 16000/27455 samples\n",
            "Looked at 19200/27455 samples\n",
            "Looked at 22400/27455 samples\n",
            "Looked at 25600/27455 samples\n",
            "\n",
            "Train loss: 0.37853, Train Accuracy:  83.4645 | Test loss: 0.00025, Test Accuracy: 100.00%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "results = train_model(model,train_dataloader,test_dataloader,optimizer,loss_fn,accuracy_fn,10,True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "bnUjmGdnaU2i"
      },
      "outputs": [],
      "source": [
        "epochs = np.arange(1,11,1)"
      ]
    }
  ]
}