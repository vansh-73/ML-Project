{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning - Mini Project"
      ],
      "metadata": {
        "id": "FB1KAv_6LlYc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing required libraries"
      ],
      "metadata": {
        "id": "0xFIB40D8Gel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWgT8s8jOw8X",
        "outputId": "391a8aa6-a8b1-46c9-9691-9d95ec9af55a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "447R0crHSoqm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D, ReLU, Dropout\n",
        "from keras.optimizers.legacy import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the CNN model"
      ],
      "metadata": {
        "id": "daMm1t2I8V55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "EPOCHS = 10\n",
        "NUM_CLASSES = 26\n",
        "image_size = (28, 28, 1)\n",
        "droupout_rate = 0.2"
      ],
      "metadata": {
        "id": "HgsGgSxXUeNS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building model\n",
        "inputs = Input(shape= image_size)\n",
        "conv1 = Conv2D(filters=32, kernel_size=(3, 3), strides=1)(inputs)\n",
        "relu1 = ReLU()(conv1)\n",
        "mxpool = MaxPooling2D(pool_size=(2, 2))(relu1)\n",
        "conv2 = Conv2D(filters=64, kernel_size=(2, 2), strides=1, padding='same')(mxpool)\n",
        "relu2 = ReLU()(conv2)\n",
        "mxpool = MaxPooling2D(pool_size=(2, 2))(relu2)\n",
        "flatten = Flatten()(mxpool)\n",
        "dense = Dense(128, activation='relu')(flatten)\n",
        "dropout = Dropout(droupout_rate)(dense)\n",
        "outputs = Dense(NUM_CLASSES, activation='softmax')(dropout)\n",
        "model = Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "JtD1STawUerN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the Dataset"
      ],
      "metadata": {
        "id": "JIAyKnwA8qqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining dataset size\n",
        "dataset = 27455\n",
        "\n",
        "# defining the dataset split\n",
        "train_ratio = 0.7\n",
        "test_ratio = 0.3"
      ],
      "metadata": {
        "id": "Re0V98RqUqOd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading csv file\n",
        "data = pd.read_csv('/content/sign_mnist_train.csv')\n",
        "\n",
        "# extracting pixel values and class number\n",
        "pixels = data.iloc[ 1:, -784: ].values\n",
        "class_numbers = data.iloc[ 1:, 0].values\n",
        "\n",
        "# converting pixel values to numpy array and reshaping\n",
        "pixels = np.array(pixels, dtype='float32').reshape(-1, 28, 28, 1)\n",
        "\n",
        "# converting class numbers to one-hot encoded labels\n",
        "class_labels = keras.utils.to_categorical(class_numbers, NUM_CLASSES)\n",
        "\n",
        "# creating train and validation data\n",
        "train_data = pixels[: int(train_ratio * dataset)]\n",
        "train_labels = class_labels[: int(train_ratio * dataset)]\n",
        "val_data = pixels[int(train_ratio * dataset): ]\n",
        "val_labels = class_labels[int(train_ratio * dataset): ]"
      ],
      "metadata": {
        "id": "wZeM9Kl0UtoK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model"
      ],
      "metadata": {
        "id": "1Nkh1vG682q7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating train generator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow(\n",
        "    x=train_data,\n",
        "    y=train_labels,\n",
        "    batch_size=batch_size)\n",
        "\n",
        "# creating validation generator\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_data = val_datagen.flow(\n",
        "    x=val_data,\n",
        "    y=val_labels,\n",
        "    batch_size=batch_size)\n",
        "\n",
        "# compiling model\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "model.compile( optimizer=opt, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs= 10,\n",
        "    validation_data=test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UP3QFAUYUyyG",
        "outputId": "e5b8f62e-9b7b-4acf-9da4-6f5f5c212cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "601/601 [==============================] - 51s 82ms/step - loss: 2.9241 - accuracy: 0.1712 - val_loss: 2.1167 - val_accuracy: 0.5174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history['loss'])\n",
        "print(history.history['accuracy'])"
      ],
      "metadata": {
        "id": "6eB4MfXO-qul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting Training/Validating Graphs"
      ],
      "metadata": {
        "id": "j9WjOvjZQXeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss over epochs\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validating Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot accuracy over epochs\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validating Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "76IrYcCuLaZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the Model"
      ],
      "metadata": {
        "id": "8x05UXWbYfQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('/content/sign_mnist_test.csv')\n",
        "pixels = test_data.iloc[ 1:, -784: ].values\n",
        "class_numbers = test_data.iloc[ 1:, 0].values\n",
        "\n",
        "# converting pixel values to numpy array and reshaping\n",
        "pixels = np.array(pixels, dtype='float32').reshape(-1, 28, 28, 1)\n",
        "\n",
        "# converting class numbers to one-hot encoded labels\n",
        "class_labels = keras.utils.to_categorical(class_numbers, NUM_CLASSES)\n",
        "\n",
        "x_test = pixels\n",
        "y_test = class_labels"
      ],
      "metadata": {
        "id": "zJU9U5mzKLFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test, verbose=1)"
      ],
      "metadata": {
        "id": "2vCVfhL6KH8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape= image_size)\n",
        "conv1 = Conv2D(filters=32, kernel_size=(3, 3), strides=1)(inputs)\n",
        "relu1 = ReLU()(conv1)\n",
        "mxpool = MaxPooling2D(pool_size=(2, 2))(relu1)\n",
        "conv2 = Conv2D(filters=64, kernel_size=(2, 2), strides=2, padding='same')(mxpool)\n",
        "relu2 = ReLU()(conv2)\n",
        "mxpool = MaxPooling2D(pool_size=(2, 2))(relu2)\n",
        "dropout = Dropout(0.3)(mxpool)\n",
        "flatten = Flatten()(dropout)\n",
        "dense = Dense(128, activation='relu')(flatten)\n",
        "dropout = Dropout(droupout_rate)(dense)\n",
        "outputs = Dense(NUM_CLASSES, activation='softmax')(dropout)\n",
        "model = Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "Su-nkM7lKvUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating train generator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow(\n",
        "    x=train_data,\n",
        "    y=train_labels,\n",
        "    batch_size=batch_size)\n",
        "\n",
        "# creating validation generator\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_data = val_datagen.flow(\n",
        "    x=val_data,\n",
        "    y=val_labels,\n",
        "    batch_size=batch_size)\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "model.compile( optimizer=opt, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs= EPOCHS,\n",
        "    validation_data=test_data)"
      ],
      "metadata": {
        "id": "3FeupDfxK6NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history['loss'])\n",
        "print(history.history['accuracy'])"
      ],
      "metadata": {
        "id": "7YUcvzTxLAD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test, verbose=1)"
      ],
      "metadata": {
        "id": "y2o_U5-YLCPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting Training/Testing Graphs"
      ],
      "metadata": {
        "id": "YwisYIfiY8D8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss over epochs\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Testing Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot accuracy over epochs\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Testing Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_ZgAOLcLN6HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing the model"
      ],
      "metadata": {
        "id": "tW-c46V7YnHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, show_shapes= True, show_layer_names= True)"
      ],
      "metadata": {
        "id": "FejVIF8jNasY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}